{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Z_Q6HdgTUsg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HNSpVluTr_4r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVXNO4qSHP7x",
        "outputId": "e0ae12da-94c3-4a94-f3ed-e9f57b040cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jmd_imagescraper in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (0.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (1.3.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (7.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (2.23.0)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (1.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (7.1.2)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from jmd_imagescraper) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->jmd_imagescraper) (4.6.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jmd_imagescraper) (1.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->jmd_imagescraper) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->jmd_imagescraper) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->jmd_imagescraper) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->jmd_imagescraper) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->jmd_imagescraper) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (5.4.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (4.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.13.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->jmd_imagescraper) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->jmd_imagescraper) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.7.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (2.16.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (22.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (5.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (4.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (3.8.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->jmd_imagescraper) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jmd_imagescraper) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jmd_imagescraper) (2022.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jmd_imagescraper) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jmd_imagescraper) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jmd_imagescraper) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jmd_imagescraper) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_utils in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch_utils) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch_utils) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!pip install jmd_imagescraper\n",
        "from jmd_imagescraper.core import *\n",
        "from jmd_imagescraper.imagecleaner import *\n",
        "from pathlib import Path\n",
        "! pip install torch_utils\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.core.common import flatten\n",
        "import copy\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "import glob\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Login"
      ],
      "metadata": {
        "id": "UWYHsOFXdQHz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BD5dqNGm1b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f91d62-b366-4a91-ac75-2929f868ac8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3HggVCdm8iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66b6ad0-14c4-498d-f59e-be316af0f6f2"
      },
      "source": [
        "#%cd gdrive/MyDrive/Colab\\ Notebooks/map_icon_finder\n",
        "#root_path = Path().cwd()/\"images\"\n",
        "root_path = '/content/images/'\n",
        "%mkdir '/content/images/'\n",
        "%cd '/content/images/'\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpqfOgxRHP7z"
      },
      "source": [
        "Datasets & DataLoaders\n",
        "===================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_NtbK-HP70"
      },
      "source": [
        "Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code\n",
        "to be decoupled from our model training code for better readability and modularity.\n",
        "PyTorch provides two data primitives: ``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``\n",
        "that allow you to use pre-loaded datasets as well as your own data.\n",
        "``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n",
        "the ``Dataset`` to enable easy access to the samples.\n",
        "\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that\n",
        "subclass ``torch.utils.data.Dataset`` and implement functions specific to the particular data.\n",
        "They can be used to prototype and benchmark your model. You can find them\n",
        "here: `Image Datasets <https://pytorch.org/vision/stable/datasets.html>`_,\n",
        "`Text Datasets  <https://pytorch.org/text/stable/datasets.html>`_, and\n",
        "`Audio Datasets <https://pytorch.org/audio/stable/datasets.html>`_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfORIilWHP71"
      },
      "source": [
        "Loading a Dataset\n",
        "-------------------\n",
        "\n",
        "Here is an example of how to load the `Fashion-MNIST <https://research.zalando.com/project/fashion_mnist/fashion_mnist/>`_ dataset from TorchVision.\n",
        "Fashion-MNIST is a dataset of Zalando’s article images consisting of 60,000 training examples and 10,000 test examples.\n",
        "Each example comprises a 28×28 grayscale image and an associated label from one of 10 classes.\n",
        "\n",
        "We load the `FashionMNIST Dataset <https://pytorch.org/vision/stable/datasets.html#fashion-mnist>`_ with the following parameters:\n",
        " - ``root`` is the path where the train/test data is stored,\n",
        " - ``train`` specifies training or test dataset,\n",
        " - ``download=True`` downloads the data from the internet if it's not available at ``root``.\n",
        " - ``transform`` and ``target_transform`` specify the feature and label transformations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y1QAGtwaHP71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c62a0c9-0954-45f4-c3f7-145ccb573cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13oTJykgbjro11OWkyQcHqkpCo1zzhbcl\n",
            "To: /content/images/images.zip\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\r100% 1.90M/1.90M [00:00<00:00, 156MB/s]\n",
            "Archive:  images.zip\n",
            "  inflating: green/green-001.png     \n",
            "  inflating: green/green-002.png     \n",
            "  inflating: green/green-003.png     \n",
            "  inflating: green/green-004.png     \n",
            "  inflating: green/green-005.png     \n",
            "  inflating: green/green-006.png     \n",
            "  inflating: green/green-007.png     \n",
            "  inflating: green/green-008.png     \n",
            " extracting: green/green-1.png       \n",
            " extracting: green/green-2.png       \n",
            "  inflating: green/green-4.png       \n",
            "  inflating: green/green-5.png       \n",
            "  inflating: green/green-arrow.png   \n",
            "  inflating: green/green-circle.png  \n",
            " extracting: other/anchor-1.png      \n",
            "  inflating: other/anchor-white.png  \n",
            "  inflating: other/anchor-yellow.png  \n",
            "  inflating: other/blue-arrow.png    \n",
            "  inflating: other/blue-circle.png   \n",
            "  inflating: other/dots.png          \n",
            "  inflating: other/gray-arrow.png    \n",
            "  inflating: other/gray-circle.png   \n",
            "  inflating: other/green-funnel.png  \n",
            "  inflating: other/helicopter.png    \n",
            "  inflating: other/lighthouse.png    \n",
            "  inflating: other/marker.png        \n",
            "  inflating: other/orange-arrow.png  \n",
            "  inflating: other/orange-circle.png  \n",
            "  inflating: other/orange-funnel.png  \n",
            "  inflating: other/picture.png       \n",
            "  inflating: other/pink-circle.png   \n",
            "  inflating: other/purple-arrow.png  \n",
            "  inflating: other/purple-circle.png  \n",
            "  inflating: other/red-funnel.png    \n",
            "  inflating: other/thing.png         \n",
            "  inflating: other/turquoise-arrow.png  \n",
            "  inflating: other/turquoise-circle.png  \n",
            " extracting: other/unknown-1.png     \n",
            " extracting: other/unknown-2.png     \n",
            "  inflating: other/white-arrow.png   \n",
            "  inflating: other/white-circle.png  \n",
            "  inflating: other/yellow-arrow.png  \n",
            "  inflating: other/yellow-circle.png  \n",
            "  inflating: red/red-001.png         \n",
            "  inflating: red/red-002.png         \n",
            "  inflating: red/red-003.png         \n",
            "  inflating: red/red-004.png         \n",
            "  inflating: red/red-005.png         \n",
            "  inflating: red/red-006.png         \n",
            "  inflating: red/red-007.png         \n",
            "  inflating: red/red-008.png         \n",
            " extracting: red/red-1.png           \n",
            " extracting: red/red-2.png           \n",
            "  inflating: red/red-arrow.png       \n",
            "  inflating: red/red-circle.png      \n",
            "  inflating: unused/0000001.jpg      \n",
            "  inflating: unused/10000011.jpg     \n",
            "  inflating: unused/1000002.jpg      \n",
            "  inflating: unused/12000013.jpg     \n",
            "  inflating: unused/14000015.jpg     \n",
            "  inflating: unused/5000006.jpg      \n",
            "  inflating: unused/6000007.jpg      \n",
            "  inflating: unused/9000010.jpg      \n",
            "  inflating: unused/green-3.png      \n",
            "  inflating: unused/map-01.png       \n",
            "  inflating: unused/map-02.png       \n",
            "  inflating: unused/map-03.png       \n",
            "  inflating: unused/map-04.png       \n",
            "  inflating: unused/map-05.png       \n",
            "root path:  /content/images/\n",
            "\u001b[0m\u001b[01;34mgreen\u001b[0m/  images.zip  \u001b[01;34mother\u001b[0m/  \u001b[01;34mred\u001b[0m/  \u001b[01;34munused\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# Download Fashion MNIST Dataset from torchvision\n",
        "\"\"\"training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\"\"\"\n",
        "\n",
        "# Download ZIP From Google Drive\n",
        "!gdown 13oTJykgbjro11OWkyQcHqkpCo1zzhbcl\n",
        "!unzip -o images.zip\n",
        "print(\"root path: \", root_path)\n",
        "%ls\n",
        "\n",
        "# Compress all images to single zip file\n",
        "#!zip -r /content/ImagesfromColab.zip /content/images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download images"
      ],
      "metadata": {
        "id": "d2faQLvztpF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#duckduckgo_search(root_path, \"Cats\", \"cute kittens\", max_results=20)"
      ],
      "metadata": {
        "id": "Nor0QgaKrL2k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train, Validate, and Test Sets"
      ],
      "metadata": {
        "id": "lmOR0_CD819e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "#       Create Train, Valid and Test sets\n",
        "####################################################\n",
        "train_data_path = 'images/train' \n",
        "test_data_path = 'images/test'\n",
        "\n",
        "train_image_paths = [] #to store image paths in list\n",
        "classes = [] #to store class values\n",
        "\n",
        "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
        "# eg. train path-> 'images/train/26.Pont_du_Gard/4321ee6695c23c7b.jpg'\n",
        "# eg. class -> 26.Pont_du_Gard\n",
        "for data_path in glob.glob(train_data_path + '/*'):\n",
        "    classes.append(data_path.split('/')[-1]) \n",
        "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
        "    \n",
        "train_image_paths = list(flatten(train_image_paths))\n",
        "random.shuffle(train_image_paths)\n",
        "\n",
        "print('train_image_path example: ', train_image_paths[0])\n",
        "print('class example: ', classes[0])\n",
        "\n",
        "# split train valid from train paths (80,20)\n",
        "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):] \n",
        "\n",
        "# create the test_image_paths\n",
        "test_image_paths = []\n",
        "for data_path in glob.glob(test_data_path + '/*'):\n",
        "    test_image_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "test_image_paths = list(flatten(test_image_paths))\n",
        "\n",
        "print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_image_paths), len(valid_image_paths), len(test_image_paths)))"
      ],
      "metadata": {
        "id": "nec5Xyzc9A2g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "862846ad-c9da-4688-dd4d-d2d257288828"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-770d3b2ad2ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_image_path example: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class example: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJCJbvFHP72"
      },
      "source": [
        "## Iterating and Visualizing the Dataset\n",
        "\n",
        "We can index ``Datasets`` manually like a list: ``training_data[index]``.\n",
        "We use ``matplotlib`` to visualize some samples in our training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display_image_cleaner(root_path) # can only display JPGs currently"
      ],
      "metadata": {
        "id": "_mW3QoRHpKW3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-6TIXS4HP72"
      },
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkIb2tbkHP73"
      },
      "source": [
        "Creating a Custom Dataset for your files\n",
        "---------------------------------------------------\n",
        "\n",
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
        "Take a look at this implementation; the FashionMNIST images are stored\n",
        "in a directory ``img_dir``, and their labels are stored separately in a CSV file ``annotations_file``.\n",
        "\n",
        "In the next sections, we'll break down what's happening in each of these functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLrK43GwHP73"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    # The __init__ function is run once when instantiating the Dataset object. \n",
        "    # We initialize the directory containing the images, the annotations file, and both transforms.\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    # The __len__ function returns the number of samples in our dataset.\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    # The __getitem__ function loads and returns a sample from the dataset at the given index ``idx``.\n",
        "    # Based on the index, it identifies the image's location on disk, converts that to a tensor using ``read_image``, retrieves the\n",
        "    # corresponding label from the csv data in ``self.img_labels``, calls the transform functions on them (if applicable), and returns the\n",
        "    # tensor image and corresponding label in a tuple.\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RHEAwDfHP75"
      },
      "source": [
        "Preparing your data for training with DataLoaders\n",
        "-------------------------------------------------\n",
        "The ``Dataset`` retrieves our dataset's features and labels one sample at a time. While training a model, we typically want to\n",
        "pass samples in \"minibatches\", reshuffle the data at every epoch to reduce model overfitting, and use Python's ``multiprocessing`` to\n",
        "speed up data retrieval.\n",
        "\n",
        "``DataLoader`` is an iterable that abstracts this complexity for us in an easy API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4VvRfnGHP75"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-D_uKm6HP75"
      },
      "source": [
        "Iterate through the DataLoader\n",
        "--------------------------\n",
        "\n",
        "We have loaded that dataset into the ``DataLoader`` and can iterate through the dataset as needed.\n",
        "Each iteration below returns a batch of ``train_features`` and ``train_labels`` (containing ``batch_size=64`` features and labels respectively).\n",
        "Because we specified ``shuffle=True``, after we iterate over all batches the data is shuffled (for finer-grained control over\n",
        "the data loading order, take a look at `Samplers <https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler>`_).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsHEcH9WHP75"
      },
      "outputs": [],
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJsKekmQHP76"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU31AdGzHP76"
      },
      "source": [
        "Further Reading\n",
        "--------------\n",
        "- `torch.utils.data API <https://pytorch.org/docs/stable/data.html>`_\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "Map_Icon_Finder.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "HNSpVluTr_4r"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}